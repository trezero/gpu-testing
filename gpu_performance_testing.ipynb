{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a09ac9c8-561b-4e52-afc0-845b4d1ef3ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Oct 29 01:08:45 2023       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.113.01             Driver Version: 535.113.01   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3060 Ti     Off | 00000000:01:00.0  On |                  N/A |\n",
      "|  0%   32C    P8              10W / 225W |    469MiB /  8192MiB |      1%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA GeForce GTX 1080        Off | 00000000:04:00.0 Off |                  N/A |\n",
      "|  0%   23C    P8               8W / 215W |      6MiB /  8192MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A      1593      G   /usr/lib/xorg/Xorg                          189MiB |\n",
      "|    0   N/A  N/A      2075      G   /usr/bin/gnome-shell                        148MiB |\n",
      "|    0   N/A  N/A      8111      G   /usr/lib/firefox/firefox                    121MiB |\n",
      "|    1   N/A  N/A      1593      G   /usr/lib/xorg/Xorg                            4MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!/usr/bin/nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1468cef7-893e-45b3-94a9-8f45bd852843",
   "metadata": {},
   "source": [
    "# Import ALL Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0c403fc-3250-47b3-a9bf-915cd389061e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "from whisper import load_model\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2e09104-a30c-4b5a-ad0a-0a1e7365f4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleMediaDir = \"/mnt/m2media/sampleMedia\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8691f2d0-a111-4335-952c-e4e4bcab04ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/m2media/sampleMedia'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampleMediaDir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c20479b3-62d5-4d86-aa31-f84dc23727f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " EAH1.mp4\n",
      "'How Did The Sriracha Shortage Happen_.mp4'\n",
      "'How Did The Sriracha Shortage Happen_.wav'\n"
     ]
    }
   ],
   "source": [
    "!ls $sampleMediaDir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d47a623-2464-4589-a8c3-cd40780509f7",
   "metadata": {},
   "source": [
    "## Set sample file to be used as audio data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1de8d811-4b1b-4c9c-bb30-105b6c62f1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = sampleMediaDir + \"/How Did The Sriracha Shortage Happen_.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85d7b340-0aeb-40e2-a207-c747bf79a98b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/m2media/sampleMedia/How Did The Sriracha Shortage Happen_.mp4'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4bc41b-22f2-4840-92df-bb7c3bd72c6f",
   "metadata": {},
   "source": [
    "## Check versions of pytorch and tourchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e582baf-ed20-4014-b529-4eed5401cd41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# packages in environment at /home/winadmin/miniconda3/envs/periferyNABNY2023py38:\n",
      "#\n",
      "# Name                    Version                   Build  Channel\n",
      "pytorch                   2.2.0.dev20231028     py3.8_cpu_0    pytorch-nightly\n",
      "pytorch-mutex             1.0                         cpu    pytorch-nightly\n",
      "# packages in environment at /home/winadmin/miniconda3/envs/periferyNABNY2023py38:\n",
      "#\n",
      "# Name                    Version                   Build  Channel\n",
      "torchaudio                2.2.0.dev20231028        py38_cpu    pytorch-nightly\n"
     ]
    }
   ],
   "source": [
    "!conda list pytorch\n",
    "!conda list torchaudio\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f235fae-9630-4496-a992-a98cec1e85b2",
   "metadata": {},
   "source": [
    "## Convert the audio portion of a video file into a PyTorch tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a059efa-dd82-4dd3-adfa-265e0ad774fe",
   "metadata": {},
   "source": [
    "### First we need to extract audio from the video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6d460b1-c08f-4a89-97c7-9c275254770a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio\n",
    "from moviepy.editor import *\n",
    "import os\n",
    "\n",
    "# Generate audio file name based on the video file name\n",
    "audio_file_name = os.path.splitext(os.path.basename(video_path))[0] + \".wav\"\n",
    "\n",
    "# Path to save the audio file\n",
    "audio_path = os.path.join(os.path.dirname(video_path), audio_file_name)\n",
    "\n",
    "# Check if the audio file already exists\n",
    "if not os.path.exists(audio_path):\n",
    "    # Load video\n",
    "    video = VideoFileClip(video_path)\n",
    "\n",
    "    # Extract audio\n",
    "    audio_data = video.audio\n",
    "\n",
    "    # Save audio\n",
    "    audio_data.write_audiofile(audio_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4257855-30bb-4211-88d6-ad453020429b",
   "metadata": {},
   "source": [
    "### Next we can convert the audio to a Pytorch Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8605e7f6-ce2a-48ed-89a7-71ad5256557d",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_waveform, sample_rate = torchaudio.load(audio_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec3019a-c24c-46a5-8875-d18d74e7131f",
   "metadata": {},
   "source": [
    "## Set the **device** to the CUDA device you wish to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb7cf07e-fb76-4882-86cd-cdf3df4179e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b2dec6-350a-4fae-84b0-aa56cfb293ff",
   "metadata": {},
   "source": [
    "### Now we can move the audio data to the specified device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4404a2e-0143-4c30-afcb-78ee65093882",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_waveform = audio_waveform.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7393089-73fb-4dfd-aa63-4285e9354da8",
   "metadata": {},
   "source": [
    "#### If you need help: Add this line: help(whisper)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95fa29cb-b85d-4689-ad76-276c2077e4fb",
   "metadata": {},
   "source": [
    "# Check if torch is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d52f28c-7749-41e1-ba1e-1f6c74d41b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33165f32-18fe-4d9c-9fbd-425190b532c4",
   "metadata": {},
   "source": [
    "# List available models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3938e52-046f-4ab9-8ed3-2d8ff596f0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "available_models = whisper.available_models()\n",
    "print(available_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691cce7f-33cb-4c9f-a480-0c7eb68e9c60",
   "metadata": {},
   "source": [
    "# Load a model (for this example, we assume the first available model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ee39b9-2bfc-497f-8616-d4ad078ea788",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = available_models[0]\n",
    "asr_model = whisper.load_model(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d299d7a9-5976-408d-a4f7-2669c07913e2",
   "metadata": {},
   "source": [
    "# Move the model to the specified device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1b3cfc-645b-418b-ab85-070f0656429a",
   "metadata": {},
   "outputs": [],
   "source": [
    "asr_model = asr_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6baeb1b7-0a79-40ed-8a76-f8cef7114b4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ed09df8a-a36a-4d3b-9cd2-307345e2fec8",
   "metadata": {},
   "source": [
    "# Use the moviepy library to determine the duration of the source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c1abed-e065-46f6-92f1-e16a4c54bf17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import AudioFileClip, VideoFileClip\n",
    "\n",
    "# Function to get duration\n",
    "def get_media_duration(audio_data):\n",
    "    if audio_data.endswith(('.mp4', '.mkv', '.webm', '.flv', '.mov', '.avi')):\n",
    "        clip = VideoFileClip(audio_data)\n",
    "    else:  # Assuming other extensions are audio files\n",
    "        clip = AudioFileClip(audio_data)\n",
    "    duration = clip.duration\n",
    "    clip.close()\n",
    "    return duration\n",
    "\n",
    "# Get and print media duration\n",
    "duration = get_media_duration(audio_data)  # Replace with the path to your audio_data\n",
    "print(f\"Media Duration: {duration} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08f7f05-40dc-4101-a1f7-017dd0346966",
   "metadata": {},
   "source": [
    "# Transcribe Audio and calculate the time taken:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed264a8-a569-4c29-bf08-c504baaa0577",
   "metadata": {},
   "source": [
    "### (Assuming audio_data is the audio file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6548f1ef-0766-42a8-bff0-8301275b2ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "transcription = asr_model.transcribe(audio_data)\n",
    "end_time = time.time()\n",
    "\n",
    "processing_time = end_time - start_time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478f4b2f-9013-43d7-a8c9-78399174b288",
   "metadata": {},
   "source": [
    "## calculate and print the performance ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f745b86-edc4-422d-9e6e-d8436b0ab696",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_ratio = duration / processing_time\n",
    "media_duration_str = f\"{duration:.2f}\"\n",
    "processing_time_str = f\"{processing_time:.2f}\"\n",
    "performance_ratio_str = f\"{performance_ratio:.2f}\"\n",
    "\n",
    "output_str = f\"Media Duration: {media_duration_str} seconds | Total Processing Time = {processing_time_str} seconds | Performance: {performance_ratio_str}x real-time\"\n",
    "print(output_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53924bb0-2bee-40c5-a3da-80f546d9e0f6",
   "metadata": {},
   "source": [
    "## Print the Transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1faba6-3de6-41d2-88dc-69607c019dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(transcription)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a345cc54-dd8d-402e-9349-39224ad38382",
   "metadata": {},
   "source": [
    "# Generate Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5fbb75a-513d-4af3-8b33-0578d42cd248",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import torch\n",
    "from datetime import datetime\n",
    "\n",
    "# Function to gather performance metrics (Placeholder, replace with actual metric gathering code)\n",
    "def gather_metrics():\n",
    "    # Replace this with code that gathers actual performance metrics\n",
    "    return {\n",
    "        \"DateTime\": datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "        \"Source File\": audio_data,\n",
    "        \"gpu_name\": torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"CPU\",\n",
    "        \"whisper_model\": model_name,\n",
    "        \"performance_metric\": f\"{performance_ratio:.2f}x real-time\"\n",
    "    }\n",
    "\n",
    "# Create or open CSV file to store performance metrics\n",
    "csv_file_path = \"gpu_performance_metrics.csv\"\n",
    "file_exists = os.path.isfile(csv_file_path)\n",
    "with open(csv_file_path, 'a', newline='') as csvfile:\n",
    "    fieldnames = [\"DateTime\", \"Source File\", \"gpu_name\", \"whisper_model\", \"performance_metric\"]\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    \n",
    "    # Write header only if the file didn't exist\n",
    "    if not file_exists:\n",
    "        writer.writeheader()\n",
    "\n",
    "    # Gather performance metrics and write to CSV\n",
    "    metrics = gather_metrics()\n",
    "    writer.writerow(metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e07ff55-0f26-4226-a3d9-5e1a8f7f2148",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "perifery102723",
   "language": "python",
   "name": "periferynabny2023py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
